{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vol/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/vol/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import AdaBoostClassifier as AdaBoost\n",
    "from sklearn.ensemble import BaggingClassifier as Bagging\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBoost\n",
    "from sklearn.ensemble import VotingClassifier as Voting\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do training data\n",
    "### Load amd check training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118529, 17)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voted</th>\n",
       "      <th>gender</th>\n",
       "      <th>cd</th>\n",
       "      <th>hd</th>\n",
       "      <th>age</th>\n",
       "      <th>dbdistance</th>\n",
       "      <th>vccdistance</th>\n",
       "      <th>party</th>\n",
       "      <th>racename</th>\n",
       "      <th>hsonly</th>\n",
       "      <th>mrrg</th>\n",
       "      <th>chldprsnt</th>\n",
       "      <th>cath</th>\n",
       "      <th>evang</th>\n",
       "      <th>nonchrst</th>\n",
       "      <th>otherchrst</th>\n",
       "      <th>days.since.reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>25.4</td>\n",
       "      <td>63.4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>39.6</td>\n",
       "      <td>27.3</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>Uncoded</td>\n",
       "      <td>7.9</td>\n",
       "      <td>97.8</td>\n",
       "      <td>59.8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.9</td>\n",
       "      <td>36.9</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>50.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>49.5</td>\n",
       "      <td>14.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>31.7</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>47.4</td>\n",
       "      <td>13.1</td>\n",
       "      <td>22.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31.4</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>30.5</td>\n",
       "      <td>19.1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>39.1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  voted gender   cd    hd  age  dbdistance  vccdistance party   racename  \\\n",
       "0     Y      M  7.0  31.0   36         NaN          NaN     U   Hispanic   \n",
       "1     Y      F  6.0  38.0   55         NaN          NaN     U    Uncoded   \n",
       "2     Y      F  2.0  53.0   24         NaN          NaN     U  Caucasian   \n",
       "3     Y      F  7.0  30.0   25         NaN          NaN     D  Caucasian   \n",
       "4     Y      M  5.0  19.0   22         NaN          NaN     R  Caucasian   \n",
       "\n",
       "   hsonly  mrrg  chldprsnt  cath  evang  nonchrst  otherchrst  days.since.reg  \n",
       "0    25.4  63.4       54.0  16.7   16.5      39.6        27.3             420  \n",
       "1     7.9  97.8       59.8  16.7   15.5      30.9        36.9             307  \n",
       "2    50.2   7.6       49.5  14.6   24.0      29.6        31.7             292  \n",
       "3    38.0   8.5       47.4  13.1   22.3      33.3        31.4             316  \n",
       "4    30.5  19.1       23.1  16.0   10.5      39.1        34.5             392  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender any null? False\n",
      "cd any null? True\n",
      "hd any null? True\n",
      "age any null? False\n",
      "dbdistance any null? True\n",
      "vccdistance any null? True\n",
      "party any null? False\n",
      "racename any null? False\n",
      "hsonly any null? False\n",
      "mrrg any null? False\n",
      "chldprsnt any null? False\n",
      "cath any null? False\n",
      "evang any null? False\n",
      "nonchrst any null? False\n",
      "otherchrst any null? False\n",
      "days.since.reg any null? False\n"
     ]
    }
   ],
   "source": [
    "# check NaN column by column\n",
    "print 'gender any null? ' + str(train['gender'].isnull().values.any())\n",
    "print 'cd any null? ' + str(train['cd'].isnull().values.any())\n",
    "print 'hd any null? ' + str(train['hd'].isnull().values.any())\n",
    "print 'age any null? ' + str(train['age'].isnull().values.any())\n",
    "print 'dbdistance any null? ' + str(train['dbdistance'].isnull().values.any())\n",
    "print 'vccdistance any null? ' + str(train['vccdistance'].isnull().values.any())\n",
    "print 'party any null? ' + str(train['party'].isnull().values.any())\n",
    "print 'racename any null? ' + str(train['racename'].isnull().values.any())\n",
    "print 'hsonly any null? ' + str(train['hsonly'].isnull().values.any())\n",
    "print 'mrrg any null? ' + str(train['mrrg'].isnull().values.any())\n",
    "print 'chldprsnt any null? ' + str(train['chldprsnt'].isnull().values.any())\n",
    "print 'cath any null? ' + str(train['cath'].isnull().values.any())\n",
    "print 'evang any null? ' + str(train['evang'].isnull().values.any())\n",
    "print 'nonchrst any null? ' + str(train['nonchrst'].isnull().values.any())\n",
    "print 'otherchrst any null? ' + str(train['otherchrst'].isnull().values.any())\n",
    "print 'days.since.reg any null? ' + str(train['days.since.reg'].isnull().values.any())\n",
    "#print 'Id any null? ' + str(train['Id'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.91094259371\n",
      "2.27622\n",
      "3.24225375615\n",
      "2.444945\n",
      "3.76732727564\n",
      "4.0\n",
      "30.9323782767\n",
      "29.0\n"
     ]
    }
   ],
   "source": [
    "print train['dbdistance'].mean()\n",
    "print train['dbdistance'].median()\n",
    "print train['vccdistance'].mean()\n",
    "print train['vccdistance'].median()\n",
    "\n",
    "print train['cd'].mean()\n",
    "print train['cd'].median()\n",
    "print train['hd'].mean()\n",
    "print train['hd'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.plot(train['dbdistance'])\n",
    "# plt.show()\n",
    "# plt.plot(train['vccdistance'])\n",
    "# plt.show()\n",
    "# plt.plot(train['voted'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill missing data\n",
    "predictors_na = ['cd', 'hd', 'dbdistance', 'vccdistance']\n",
    "train_filled = pd.DataFrame(train)\n",
    "train_filled[predictors_na] = train_filled[predictors_na].apply(lambda x:x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd any null? False\n",
      "hd any null? False\n",
      "dbdistance any null? False\n",
      "vccdistance any null? False\n"
     ]
    }
   ],
   "source": [
    "print 'cd any null? ' + str(train_filled['cd'].isnull().values.any())\n",
    "print 'hd any null? ' + str(train_filled['hd'].isnull().values.any())\n",
    "print 'dbdistance any null? ' + str(train_filled['dbdistance'].isnull().values.any())\n",
    "print 'vccdistance any null? ' + str(train_filled['vccdistance'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_filled['newage'] = np.log(train_filled['age'])\n",
    "# train_filled['newage'] = train_filled['age']\n",
    "\n",
    "train_filled['newchldprsnt'] = np.sqrt(train_filled['chldprsnt'])\n",
    "# train_filled['newchldprsnt'] = train_filled['chldprsnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(train_filled['dbdistance'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do one-hot encoding and split my_train and my_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>cd</th>\n",
       "      <th>hd</th>\n",
       "      <th>newage</th>\n",
       "      <th>dbdistance</th>\n",
       "      <th>vccdistance</th>\n",
       "      <th>party</th>\n",
       "      <th>racename</th>\n",
       "      <th>hsonly</th>\n",
       "      <th>mrrg</th>\n",
       "      <th>newchldprsnt</th>\n",
       "      <th>cath</th>\n",
       "      <th>evang</th>\n",
       "      <th>nonchrst</th>\n",
       "      <th>otherchrst</th>\n",
       "      <th>days.since.reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>7.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>2.27622</td>\n",
       "      <td>2.444945</td>\n",
       "      <td>U</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>25.4</td>\n",
       "      <td>63.4</td>\n",
       "      <td>7.348469</td>\n",
       "      <td>16.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>39.6</td>\n",
       "      <td>27.3</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.007333</td>\n",
       "      <td>2.27622</td>\n",
       "      <td>2.444945</td>\n",
       "      <td>U</td>\n",
       "      <td>Uncoded</td>\n",
       "      <td>7.9</td>\n",
       "      <td>97.8</td>\n",
       "      <td>7.733046</td>\n",
       "      <td>16.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>30.9</td>\n",
       "      <td>36.9</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>2.27622</td>\n",
       "      <td>2.444945</td>\n",
       "      <td>U</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>50.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.035624</td>\n",
       "      <td>14.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>31.7</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>2.27622</td>\n",
       "      <td>2.444945</td>\n",
       "      <td>D</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.884766</td>\n",
       "      <td>13.1</td>\n",
       "      <td>22.3</td>\n",
       "      <td>33.3</td>\n",
       "      <td>31.4</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>2.27622</td>\n",
       "      <td>2.444945</td>\n",
       "      <td>R</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>30.5</td>\n",
       "      <td>19.1</td>\n",
       "      <td>4.806246</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>39.1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender   cd    hd    newage  dbdistance  vccdistance party   racename  \\\n",
       "0      M  7.0  31.0  3.583519     2.27622     2.444945     U   Hispanic   \n",
       "1      F  6.0  38.0  4.007333     2.27622     2.444945     U    Uncoded   \n",
       "2      F  2.0  53.0  3.178054     2.27622     2.444945     U  Caucasian   \n",
       "3      F  7.0  30.0  3.218876     2.27622     2.444945     D  Caucasian   \n",
       "4      M  5.0  19.0  3.091042     2.27622     2.444945     R  Caucasian   \n",
       "\n",
       "   hsonly  mrrg  newchldprsnt  cath  evang  nonchrst  otherchrst  \\\n",
       "0    25.4  63.4      7.348469  16.7   16.5      39.6        27.3   \n",
       "1     7.9  97.8      7.733046  16.7   15.5      30.9        36.9   \n",
       "2    50.2   7.6      7.035624  14.6   24.0      29.6        31.7   \n",
       "3    38.0   8.5      6.884766  13.1   22.3      33.3        31.4   \n",
       "4    30.5  19.1      4.806246  16.0   10.5      39.1        34.5   \n",
       "\n",
       "   days.since.reg  \n",
       "0             420  \n",
       "1             307  \n",
       "2             292  \n",
       "3             316  \n",
       "4             392  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding categorical predictors\n",
    "predictors = ['gender', 'cd', 'hd', 'newage', 'dbdistance', 'vccdistance',\n",
    "       'party', 'racename', 'hsonly', 'mrrg', 'newchldprsnt', 'cath', 'evang',\n",
    "       'nonchrst', 'otherchrst', 'days.since.reg']\n",
    "cate = ['gender', 'cd', 'hd', 'party', 'racename', ]\n",
    "\n",
    "# predictors = ['gender', 'cd', 'hd', 'newage','party', 'racename', \n",
    "#               'hsonly', 'mrrg', 'newchldprsnt','evang',\n",
    "#               'nonchrst', 'otherchrst', 'days.since.reg']\n",
    "# cate = ['gender', 'cd', 'hd', 'party', 'racename', ]\n",
    "\n",
    "df_x=pd.DataFrame(train_filled[predictors])\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118529, 103)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding 'gender'\n",
    "onehot = pd.get_dummies(df_x['gender'],prefix='gen')\n",
    "df_x = df_x.drop('gender', axis=1)\n",
    "df_x = df_x.join(onehot)\n",
    "\n",
    "# one hot encoding 'cd'\n",
    "onehot = pd.get_dummies(df_x['cd'],prefix='cd')\n",
    "df_x = df_x.drop('cd', axis=1)\n",
    "df_x = df_x.join(onehot)\n",
    "\n",
    "# one hot encoding 'hd'\n",
    "onehot = pd.get_dummies(df_x['hd'],prefix='hd')\n",
    "df_x = df_x.drop('hd', axis=1)\n",
    "df_x = df_x.join(onehot)\n",
    "\n",
    "# one hot encoding 'party'\n",
    "onehot = pd.get_dummies(df_x['party'],prefix='pty')\n",
    "df_x = df_x.drop('party', axis=1)\n",
    "df_x = df_x.join(onehot)\n",
    "\n",
    "# one hot encoding 'racename'\n",
    "onehot = pd.get_dummies(df_x['racename'])\n",
    "df_x = df_x.drop('racename', axis=1)\n",
    "df_x = df_x.join(onehot)\n",
    "\n",
    "df_x.head(7)\n",
    "print df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# separate x, y\n",
    "x=df_x.values\n",
    "y=train_filled['voted'].values\n",
    "# print x[0:3,:]\n",
    "# print y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly split into train and test sets\n",
    "my_x_train, my_x_test, my_y_train, my_y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do testing data\n",
    "### Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39510, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>cd</th>\n",
       "      <th>hd</th>\n",
       "      <th>age</th>\n",
       "      <th>dbdistance</th>\n",
       "      <th>vccdistance</th>\n",
       "      <th>party</th>\n",
       "      <th>racename</th>\n",
       "      <th>hsonly</th>\n",
       "      <th>mrrg</th>\n",
       "      <th>chldprsnt</th>\n",
       "      <th>cath</th>\n",
       "      <th>evang</th>\n",
       "      <th>nonchrst</th>\n",
       "      <th>otherchrst</th>\n",
       "      <th>days.since.reg</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>19.5</td>\n",
       "      <td>21.2</td>\n",
       "      <td>25.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>16.6</td>\n",
       "      <td>45.2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>39.7</td>\n",
       "      <td>20.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>41.4</td>\n",
       "      <td>32.2</td>\n",
       "      <td>668</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>11.3</td>\n",
       "      <td>62.7</td>\n",
       "      <td>41.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>606</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>32.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>33.1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>44.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>565</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>Uncoded</td>\n",
       "      <td>10.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>43.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>336</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender   cd    hd  age  dbdistance  vccdistance party   racename  hsonly  \\\n",
       "0      M  2.0  52.0   30         NaN          NaN     L  Caucasian    19.5   \n",
       "1      F  5.0  19.0   20         NaN          NaN     U  Caucasian    39.7   \n",
       "2      M  4.0  44.0   56         NaN          NaN     R  Caucasian    11.3   \n",
       "3      F  7.0  34.0   20         NaN          NaN     R  Caucasian    32.8   \n",
       "4      F  6.0  41.0   26         NaN          NaN     D    Uncoded    10.2   \n",
       "\n",
       "   mrrg  chldprsnt  cath  evang  nonchrst  otherchrst  days.since.reg  Id  \n",
       "0  21.2       25.3   9.8   16.6      45.2        28.4             393   1  \n",
       "1  20.2       29.1  12.0   14.4      41.4        32.2             668   2  \n",
       "2  62.7       41.3  14.8   14.7      36.0        34.6             606   3  \n",
       "3  11.6       33.1  14.5   10.3      44.6        30.6             565   4  \n",
       "4  14.7       22.4   8.2   18.4      43.5        29.9             336   5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "print test.shape\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and fill missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender any null? False\n",
      "cd any null? True\n",
      "hd any null? True\n",
      "age any null? False\n",
      "dbdistance any null? True\n",
      "vccdistance any null? True\n",
      "party any null? False\n",
      "racename any null? False\n",
      "hsonly any null? False\n",
      "mrrg any null? False\n",
      "chldprsnt any null? False\n",
      "cath any null? False\n",
      "evang any null? False\n",
      "nonchrst any null? False\n",
      "otherchrst any null? False\n",
      "days.since.reg any null? False\n",
      "Id any null? False\n"
     ]
    }
   ],
   "source": [
    "# check NaN column by column\n",
    "print 'gender any null? ' + str(test['gender'].isnull().values.any())\n",
    "print 'cd any null? ' + str(test['cd'].isnull().values.any())\n",
    "print 'hd any null? ' + str(test['hd'].isnull().values.any())\n",
    "print 'age any null? ' + str(test['age'].isnull().values.any())\n",
    "print 'dbdistance any null? ' + str(test['dbdistance'].isnull().values.any())\n",
    "print 'vccdistance any null? ' + str(test['vccdistance'].isnull().values.any())\n",
    "print 'party any null? ' + str(test['party'].isnull().values.any())\n",
    "print 'racename any null? ' + str(test['racename'].isnull().values.any())\n",
    "print 'hsonly any null? ' + str(test['hsonly'].isnull().values.any())\n",
    "print 'mrrg any null? ' + str(test['mrrg'].isnull().values.any())\n",
    "print 'chldprsnt any null? ' + str(test['chldprsnt'].isnull().values.any())\n",
    "print 'cath any null? ' + str(test['cath'].isnull().values.any())\n",
    "print 'evang any null? ' + str(test['evang'].isnull().values.any())\n",
    "print 'nonchrst any null? ' + str(test['nonchrst'].isnull().values.any())\n",
    "print 'otherchrst any null? ' + str(test['otherchrst'].isnull().values.any())\n",
    "print 'days.since.reg any null? ' + str(test['days.since.reg'].isnull().values.any())\n",
    "print 'Id any null? ' + str(test['Id'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing data\n",
    "predictors_na = ['cd', 'hd', 'dbdistance', 'vccdistance']\n",
    "test_filled = pd.DataFrame(test)\n",
    "test_filled[predictors_na] = test_filled[predictors_na].apply(lambda x:x.fillna(x.median()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_filled['newage'] = np.log(test_filled['age'])\n",
    "# test_filled['newchldprsnt'] = np.sqrt(test_filled['chldprsnt'])\n",
    "\n",
    "test_filled['newage'] = (test_filled['age'])\n",
    "test_filled['newchldprsnt'] = (test_filled['chldprsnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do one-hot encoding and split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>cd</th>\n",
       "      <th>hd</th>\n",
       "      <th>newage</th>\n",
       "      <th>dbdistance</th>\n",
       "      <th>vccdistance</th>\n",
       "      <th>party</th>\n",
       "      <th>racename</th>\n",
       "      <th>hsonly</th>\n",
       "      <th>mrrg</th>\n",
       "      <th>newchldprsnt</th>\n",
       "      <th>cath</th>\n",
       "      <th>evang</th>\n",
       "      <th>nonchrst</th>\n",
       "      <th>otherchrst</th>\n",
       "      <th>days.since.reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2.296225</td>\n",
       "      <td>2.4741</td>\n",
       "      <td>L</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>19.5</td>\n",
       "      <td>21.2</td>\n",
       "      <td>25.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>16.6</td>\n",
       "      <td>45.2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2.296225</td>\n",
       "      <td>2.4741</td>\n",
       "      <td>U</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>39.7</td>\n",
       "      <td>20.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>41.4</td>\n",
       "      <td>32.2</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56</td>\n",
       "      <td>2.296225</td>\n",
       "      <td>2.4741</td>\n",
       "      <td>R</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>11.3</td>\n",
       "      <td>62.7</td>\n",
       "      <td>41.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>14.7</td>\n",
       "      <td>36.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2.296225</td>\n",
       "      <td>2.4741</td>\n",
       "      <td>R</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>32.8</td>\n",
       "      <td>11.6</td>\n",
       "      <td>33.1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>44.6</td>\n",
       "      <td>30.6</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2.296225</td>\n",
       "      <td>2.4741</td>\n",
       "      <td>D</td>\n",
       "      <td>Uncoded</td>\n",
       "      <td>10.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>43.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender   cd    hd  newage  dbdistance  vccdistance party   racename  hsonly  \\\n",
       "0      M  2.0  52.0      30    2.296225       2.4741     L  Caucasian    19.5   \n",
       "1      F  5.0  19.0      20    2.296225       2.4741     U  Caucasian    39.7   \n",
       "2      M  4.0  44.0      56    2.296225       2.4741     R  Caucasian    11.3   \n",
       "3      F  7.0  34.0      20    2.296225       2.4741     R  Caucasian    32.8   \n",
       "4      F  6.0  41.0      26    2.296225       2.4741     D    Uncoded    10.2   \n",
       "\n",
       "   mrrg  newchldprsnt  cath  evang  nonchrst  otherchrst  days.since.reg  \n",
       "0  21.2          25.3   9.8   16.6      45.2        28.4             393  \n",
       "1  20.2          29.1  12.0   14.4      41.4        32.2             668  \n",
       "2  62.7          41.3  14.8   14.7      36.0        34.6             606  \n",
       "3  11.6          33.1  14.5   10.3      44.6        30.6             565  \n",
       "4  14.7          22.4   8.2   18.4      43.5        29.9             336  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding categorical predictors\n",
    "predictors = ['gender', 'cd', 'hd', 'newage', 'dbdistance', 'vccdistance',\n",
    "       'party', 'racename', 'hsonly', 'mrrg', 'newchldprsnt', 'cath', 'evang',\n",
    "       'nonchrst', 'otherchrst', 'days.since.reg']\n",
    "cate = ['gender', 'cd', 'hd', 'party', 'racename', ]\n",
    "\n",
    "# predictors = ['gender', 'cd', 'hd', 'newage',\n",
    "#        'party', 'racename', 'hsonly', 'mrrg', 'newchldprsnt','evang',\n",
    "#        'nonchrst', 'otherchrst', 'days.since.reg']\n",
    "# cate = ['gender', 'cd', 'hd', 'party', 'racename', ]\n",
    "\n",
    "df_test_x=pd.DataFrame(test_filled[predictors])\n",
    "df_test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39510, 103)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding 'gender'\n",
    "onehot = pd.get_dummies(df_test_x['gender'],prefix='gen')\n",
    "df_test_x = df_test_x.drop('gender', axis=1)\n",
    "df_test_x = df_test_x.join(onehot)\n",
    "\n",
    "# one hot encoding 'cd'\n",
    "onehot = pd.get_dummies(df_test_x['cd'],prefix='cd')\n",
    "df_test_x = df_test_x.drop('cd', axis=1)\n",
    "df_test_x = df_test_x.join(onehot)\n",
    "\n",
    "# one hot encoding 'hd'\n",
    "onehot = pd.get_dummies(df_test_x['hd'],prefix='hd')\n",
    "df_test_x = df_test_x.drop('hd', axis=1)\n",
    "df_test_x = df_test_x.join(onehot)\n",
    "\n",
    "# one hot encoding 'party'\n",
    "onehot = pd.get_dummies(df_test_x['party'],prefix='pty')\n",
    "df_test_x = df_test_x.drop('party', axis=1)\n",
    "df_test_x = df_test_x.join(onehot)\n",
    "\n",
    "# one hot encoding 'racename'\n",
    "onehot = pd.get_dummies(df_test_x['racename'])\n",
    "df_test_x = df_test_x.drop('racename', axis=1)\n",
    "df_test_x = df_test_x.join(onehot)\n",
    "\n",
    "df_test_x.head(7)\n",
    "print df_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# separate x\n",
    "test_x=df_test_x.values\n",
    "# print test_x[0:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch by cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------\n",
    "# A generic function to do CV\n",
    "# --------------\n",
    "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discrepancy(xx, yy):\n",
    "    res = []\n",
    "    for x, y in zip(xx, yy):\n",
    "        res.append(-x*np.log(y)-(1-x)*np.log(1-y))\n",
    "    return np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_y_train_BOOL=(my_y_train == 'Y')*1\n",
    "my_y_test_BOOL=(my_y_test == 'Y')*1\n",
    "dtrain = xgb.DMatrix(my_x_train, label = my_y_train_BOOL)\n",
    "dtest = xgb.DMatrix(my_x_test, label = my_y_test_BOOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# param = {'max_depth':10, 'eta':0.15, 'silent':1, \n",
    "#          'objective':'binary:logistic',\n",
    "#          'min_child_weight':2,'gamma':10 }  \n",
    "param = {'max_depth':8, 'eta':0.15, 'silent':1, \n",
    "         'objective':'binary:logistic',\n",
    "         'min_child_weight':2,'gamma':6,'nthread':4}  \n",
    "watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-error:0.30024\ttrain-error:0.294996\n",
      "[1]\teval-error:0.29592\ttrain-error:0.292454\n",
      "[2]\teval-error:0.2943\ttrain-error:0.292589\n",
      "[3]\teval-error:0.294604\ttrain-error:0.290531\n",
      "[4]\teval-error:0.293085\ttrain-error:0.289316\n",
      "[5]\teval-error:0.29403\ttrain-error:0.288607\n",
      "[6]\teval-error:0.29268\ttrain-error:0.287122\n",
      "[7]\teval-error:0.291297\ttrain-error:0.284928\n",
      "[8]\teval-error:0.291196\ttrain-error:0.284613\n",
      "[9]\teval-error:0.290959\ttrain-error:0.283567\n",
      "[10]\teval-error:0.29015\ttrain-error:0.282622\n",
      "[11]\teval-error:0.289778\ttrain-error:0.281576\n",
      "[12]\teval-error:0.289205\ttrain-error:0.280564\n",
      "[13]\teval-error:0.287787\ttrain-error:0.27945\n",
      "[14]\teval-error:0.287112\ttrain-error:0.278528\n",
      "[15]\teval-error:0.287416\ttrain-error:0.278449\n",
      "[16]\teval-error:0.287754\ttrain-error:0.277628\n",
      "[17]\teval-error:0.288293\ttrain-error:0.276627\n",
      "[18]\teval-error:0.28772\ttrain-error:0.276368\n",
      "[19]\teval-error:0.287247\ttrain-error:0.275952\n",
      "[20]\teval-error:0.286977\ttrain-error:0.274928\n",
      "[21]\teval-error:0.286674\ttrain-error:0.274129\n",
      "[22]\teval-error:0.286572\ttrain-error:0.273601\n",
      "[23]\teval-error:0.286606\ttrain-error:0.273353\n",
      "[24]\teval-error:0.286235\ttrain-error:0.272599\n",
      "[25]\teval-error:0.286066\ttrain-error:0.272296\n",
      "[26]\teval-error:0.285931\ttrain-error:0.271801\n",
      "[27]\teval-error:0.28556\ttrain-error:0.271216\n",
      "[28]\teval-error:0.285189\ttrain-error:0.270485\n",
      "[29]\teval-error:0.285054\ttrain-error:0.270395\n",
      "[30]\teval-error:0.28529\ttrain-error:0.269641\n",
      "[31]\teval-error:0.285088\ttrain-error:0.269607\n",
      "[32]\teval-error:0.285594\ttrain-error:0.268955\n",
      "[33]\teval-error:0.285661\ttrain-error:0.26873\n",
      "[34]\teval-error:0.28556\ttrain-error:0.268235\n",
      "[35]\teval-error:0.285121\ttrain-error:0.26783\n",
      "[36]\teval-error:0.285594\ttrain-error:0.267717\n",
      "[37]\teval-error:0.285459\ttrain-error:0.267222\n",
      "[38]\teval-error:0.285729\ttrain-error:0.267189\n",
      "[39]\teval-error:0.285526\ttrain-error:0.266952\n",
      "[40]\teval-error:0.285459\ttrain-error:0.266885\n",
      "[41]\teval-error:0.285121\ttrain-error:0.266592\n",
      "[42]\teval-error:0.284986\ttrain-error:0.266502\n",
      "[43]\teval-error:0.284716\ttrain-error:0.266221\n",
      "[44]\teval-error:0.284784\ttrain-error:0.265985\n",
      "[45]\teval-error:0.28475\ttrain-error:0.265872\n",
      "[46]\teval-error:0.284649\ttrain-error:0.26585\n",
      "[47]\teval-error:0.284311\ttrain-error:0.265749\n",
      "[48]\teval-error:0.284109\ttrain-error:0.265344\n",
      "[49]\teval-error:0.28448\ttrain-error:0.265198\n",
      "[50]\teval-error:0.284615\ttrain-error:0.265198\n",
      "[51]\teval-error:0.284851\ttrain-error:0.26486\n",
      "[52]\teval-error:0.284885\ttrain-error:0.264399\n",
      "[53]\teval-error:0.285155\ttrain-error:0.264331\n",
      "[54]\teval-error:0.284986\ttrain-error:0.264365\n",
      "[55]\teval-error:0.285121\ttrain-error:0.264196\n",
      "[56]\teval-error:0.285121\ttrain-error:0.263949\n",
      "[57]\teval-error:0.284953\ttrain-error:0.263701\n",
      "[58]\teval-error:0.284784\ttrain-error:0.263454\n",
      "[59]\teval-error:0.28475\ttrain-error:0.263285\n",
      "[60]\teval-error:0.284581\ttrain-error:0.263274\n",
      "[61]\teval-error:0.284581\ttrain-error:0.263274\n",
      "[62]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[63]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[64]\teval-error:0.284615\ttrain-error:0.263251\n",
      "[65]\teval-error:0.284615\ttrain-error:0.263251\n",
      "[66]\teval-error:0.284615\ttrain-error:0.263251\n",
      "[67]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[68]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[69]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[70]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[71]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[72]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[73]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[74]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[75]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[76]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[77]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[78]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[79]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[80]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[81]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[82]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[83]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[84]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[85]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[86]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[87]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[88]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[89]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[90]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[91]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[92]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[93]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[94]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[95]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[96]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[97]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[98]\teval-error:0.284615\ttrain-error:0.263263\n",
      "[99]\teval-error:0.284615\ttrain-error:0.263263\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "bst = xgb.train(param,dtrain,num_round,watchlist)\n",
    "# compute_time = time.time() - start_time\n",
    "# print compute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds=bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.284615\n",
      "correct=0.715385\n"
     ]
    }
   ],
   "source": [
    "labels = dtest.get_label()  \n",
    "print ('error=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))))  \n",
    "print ('correct=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)==labels[i]) /float(len(preds))))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5564382309120639"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrepancy(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose parameters\n",
    "max_depths = [6,8,10,12]\n",
    "etas = [0.05,0.1,0.15,0.2]\n",
    "min_child_weights = [1,2,4,6]\n",
    "gammas=[2,6,10,12]\n",
    "\n",
    "dis_old = 1\n",
    "mmdd = 10\n",
    "eett = 0.15\n",
    "mmccww = 2\n",
    "ggaa = 10\n",
    "\n",
    "for md in max_depths:\n",
    "    for et in etas:\n",
    "        for mcw in min_child_weights:\n",
    "            for ga in gammas:\n",
    "                param['max_depth'] = md\n",
    "                param['eta'] = et\n",
    "                param['min_child_weight']=mcw\n",
    "                param['gamma']=ga\n",
    "                bst = xgb.train(param,dtrain,num_round)\n",
    "                preds=bst.predict(dtest)\n",
    "                dis = discrepancy(labels, preds)\n",
    "                if dis < dis_old:\n",
    "                    dis_old = dis\n",
    "                    mmdd = md\n",
    "                    eett = et\n",
    "                    mmccww = mcw\n",
    "                    ggaa = ga\n",
    "                    print dis_old,mmdd,eett,mmccww,ggaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88896, 103)\n",
      "[   2.94443898    2.27622       2.444945     68.3           6.5\n",
      "    6.43428318   15.8          22.2          29.6          32.4         293.\n",
      "    1.            0.            0.            0.        ]\n"
     ]
    }
   ],
   "source": [
    "print my_x_train.shape\n",
    "print my_x_train[0][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8903717579 4.61512051684\n",
      "1.77177 45.9893\n",
      "1.77177 45.9893\n",
      "4.0 84.3\n",
      "2.7 99.7\n",
      "0.948683298051 9.5078914592\n",
      "4.6 74.1\n",
      "1.6 56.5\n",
      "4.7 74.4\n",
      "9.5 50.8\n",
      "223.0 677.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print min(my_x_train[:,i]), max(my_x_train[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff_number = 11\n",
    "tt_number = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2.94443898,    2.27622   ,    2.444945  ,   68.3       ,\n",
       "          6.5       ,    6.43428318,   15.8       ,   22.2       ,\n",
       "         29.6       ,   32.4       ,  293.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_x_train_temp = my_x_train[:,0:ff_number]\n",
    "my_x_test_temp = my_x_test[:,0:ff_number]\n",
    "my_x_train_temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "my_x_train_scale_temp = preprocessing.scale(my_x_train_temp, axis = 0)\n",
    "my_x_train_scale = np.zeros((88896,tt_number))\n",
    "my_x_train_scale[:,0:ff_number] = my_x_train_scale_temp\n",
    "my_x_train_scale[:,ff_number:] = my_x_train[:,ff_number:]\n",
    "\n",
    "\n",
    "my_x_test_scale_temp = preprocessing.scale(my_x_test_temp, axis = 0)\n",
    "my_x_test_scale = np.zeros((29633,tt_number))\n",
    "my_x_test_scale[:,0:ff_number] = my_x_test_scale_temp\n",
    "my_x_test_scale[:,ff_number:] = my_x_test[:,ff_number:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_x_train_scale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-50c19d8358c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mmy_x_train_scale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmy_x_test_scale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_x_train_scale' is not defined"
     ]
    }
   ],
   "source": [
    "print my_x_train_scale[0]\n",
    "print my_x_test_scale[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4  -0.38 -0.38 ..., -0.27  0.24 -0.37]\n",
      " [ 0.46 -0.38 -0.38 ..., -0.4  -0.4   0.53]\n",
      " [-0.15 -0.38 -0.38 ...,  0.4  -0.05  0.54]\n",
      " ..., \n",
      " [ 0.45 -0.38 -0.38 ...,  0.45 -0.17  0.4 ]\n",
      " [-0.21 -0.38 -0.38 ..., -0.28  0.1  -0.29]\n",
      " [-0.21 -0.38 -0.38 ...,  0.42 -0.39  0.5 ]]\n"
     ]
    }
   ],
   "source": [
    "quantiles = []\n",
    "sample_num, fea_num = my_x_train_temp.shape\n",
    "step = sample_num/99\n",
    "for i in range(fea_num):\n",
    "    tmp = sorted(my_x_train_temp[:,i])\n",
    "    cur_row = step\n",
    "    quant = []\n",
    "    while cur_row < sample_num:\n",
    "        quant.append(tmp[cur_row])\n",
    "        cur_row += step\n",
    "    quantiles.append(quant)\n",
    "# print(len(quantiles[0]))\n",
    "\n",
    "new_my_x_train_temp = my_x_train_temp.copy()\n",
    "for fea_id in range(fea_num):\n",
    "    for i in range(sample_num):\n",
    "        val = my_x_train_temp[i, fea_id]\n",
    "        num_greater = np.sum(val>quantiles[fea_id])\n",
    "        new_my_x_train_temp[i, fea_id] = -0.4 + num_greater*0.01\n",
    "print(new_my_x_train_temp)\n",
    "    # my_x_train_scale_temp = preprocessing.scale(my_x_train_temp, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(my_x_train[:,1], bins=10)\n",
    "# # plt.hist(new_my_x_train_temp[:,0])\n",
    "# plt.show()\n",
    "# # print min(my_x_train[:,1]), max(my_x_train[:,1])\n",
    "# # print(sorted(my_x_train_temp[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07464497840172786"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(new_my_x_train_temp[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_x_train_scale = np.zeros((88896,tt_number))\n",
    "my_x_train_scale.shape\n",
    "# my_x_train_scale[:,0:11] = my_x_train_scale_temp\n",
    "my_x_train_scale[:,0:ff_number] = new_my_x_train_temp\n",
    "my_x_train_scale[:,ff_number:] = my_x_train[:,ff_number:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### normalization\n",
    "my_x_test_temp = my_x_test[:,0:ff_number]\n",
    "# my_x_test_scale_temp = preprocessing.scale(my_x_test_temp, axis = 0)\n",
    "new_my_x_test_temp = my_x_test_temp.copy()\n",
    "for fea_id in range(new_my_x_test_temp.shape[1]):\n",
    "    for i in range(new_my_x_test_temp.shape[0]):\n",
    "        val = my_x_test_temp[i, fea_id]\n",
    "        num_greater = np.sum(val>quantiles[fea_id])\n",
    "        new_my_x_test_temp[i, fea_id] = -0.4 + num_greater*0.01\n",
    "\n",
    "# print(my_x_test_temp)\n",
    "my_x_test_scale = np.zeros((29633,tt_number))\n",
    "# my_x_test_scale[:,0:11] = my_x_test_scale_temp\n",
    "my_x_test_scale[:,0:ff_number] = new_my_x_test_temp\n",
    "my_x_test_scale[:,ff_number:] = my_x_test[:,ff_number:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.56, -0.38, -0.38,  0.32,  0.16, -0.19,  0.46,  0.54, -0.36,\n",
       "        0.28,  0.43,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_x_test_scale[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46, -0.38, -0.38,  0.17,  0.49, -0.18,  0.58,  0.18, -0.4 ,\n",
       "       -0.4 ,  0.53,  0.  ,  1.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "        0.  ,  1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ,\n",
       "        0.  ,  0.  ,  0.  ,  0.  ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_x_train_scale[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88896 samples, validate on 29633 samples\n",
      "Epoch 1/20\n",
      "2s - loss: 0.5756 - acc: 0.7034 - val_loss: 0.5694 - val_acc: 0.7099\n",
      "Epoch 2/20\n",
      "2s - loss: 0.5718 - acc: 0.7053 - val_loss: 0.5813 - val_acc: 0.7092\n",
      "Epoch 3/20\n",
      "2s - loss: 0.5712 - acc: 0.7053 - val_loss: 0.5685 - val_acc: 0.7110\n",
      "Epoch 4/20\n",
      "2s - loss: 0.5703 - acc: 0.7060 - val_loss: 0.5721 - val_acc: 0.7084\n",
      "Epoch 5/20\n",
      "2s - loss: 0.5693 - acc: 0.7067 - val_loss: 0.5684 - val_acc: 0.7088\n",
      "Epoch 6/20\n",
      "2s - loss: 0.5677 - acc: 0.7077 - val_loss: 0.5665 - val_acc: 0.7100\n",
      "Epoch 7/20\n",
      "2s - loss: 0.5661 - acc: 0.7079 - val_loss: 0.5638 - val_acc: 0.7115\n",
      "Epoch 8/20\n",
      "2s - loss: 0.5644 - acc: 0.7083 - val_loss: 0.5642 - val_acc: 0.7096\n",
      "Epoch 9/20\n",
      "2s - loss: 0.5621 - acc: 0.7102 - val_loss: 0.5648 - val_acc: 0.7110\n",
      "Epoch 10/20\n",
      "2s - loss: 0.5608 - acc: 0.7106 - val_loss: 0.5649 - val_acc: 0.7123\n",
      "Epoch 11/20\n",
      "2s - loss: 0.5605 - acc: 0.7109 - val_loss: 0.5628 - val_acc: 0.7121\n",
      "Epoch 12/20\n",
      "2s - loss: 0.5598 - acc: 0.7114 - val_loss: 0.5623 - val_acc: 0.7125\n",
      "Epoch 13/20\n",
      "2s - loss: 0.5593 - acc: 0.7128 - val_loss: 0.5616 - val_acc: 0.7125\n",
      "Epoch 14/20\n",
      "2s - loss: 0.5588 - acc: 0.7126 - val_loss: 0.5640 - val_acc: 0.7091\n",
      "Epoch 15/20\n",
      "3s - loss: 0.5580 - acc: 0.7130 - val_loss: 0.5633 - val_acc: 0.7082\n",
      "Epoch 16/20\n",
      "3s - loss: 0.5577 - acc: 0.7132 - val_loss: 0.5632 - val_acc: 0.7060\n",
      "Epoch 17/20\n",
      "3s - loss: 0.5570 - acc: 0.7149 - val_loss: 0.5625 - val_acc: 0.7118\n",
      "Epoch 18/20\n",
      "3s - loss: 0.5568 - acc: 0.7139 - val_loss: 0.5627 - val_acc: 0.7110\n",
      "Epoch 19/20\n",
      "2s - loss: 0.5560 - acc: 0.7143 - val_loss: 0.5614 - val_acc: 0.7115\n",
      "Epoch 20/20\n",
      "2s - loss: 0.5560 - acc: 0.7149 - val_loss: 0.5630 - val_acc: 0.7077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1380dd290>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create first network with Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy\n",
    "from keras import optimizers\n",
    "# fix random seed for reproducibility\n",
    "seed = 10\n",
    "numpy.random.seed(seed)\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=103, kernel_initializer='normal', activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Dense(128, kernel_initializer='normal', activation='tanh'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(64, kernel_initializer='normal', activation='tanh'))\n",
    "# model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "# Compile model\n",
    "# sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=\"adam\", \n",
    "              metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(my_x_train_scale, my_y_train_BOOL, \n",
    "          validation_data=(my_x_test_scale, my_y_test_BOOL), \n",
    "          epochs=20, batch_size=32, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88832/88896 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "acc: 72.40%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(my_x_train_scale, my_y_train_BOOL)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.292276\n",
      "correct=0.707724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56301671"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(my_x_test_scale)\n",
    "labels = my_y_test_BOOL \n",
    "print ('error=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))))  \n",
    "print ('correct=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)==labels[i]) /float(len(preds))))  \n",
    "discrepancy(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # reshape to be [samples][pixels][width][height]\n",
    "# my_x_train_new = my_x_train[:,0:100]\n",
    "# X_train_cnn = my_x_train_new.reshape(my_x_train_new.shape[0], 1, 10, 10).astype('float32')\n",
    "# # X_test_cnn = X_test.reshape(X_test.shape[0], 1, 11, 10).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "# from keras.layers.convolutional import MaxPooling2D\n",
    "# from keras.utils import np_utils\n",
    "\n",
    "# # fix random seed for reproducibility\n",
    "# seed = 7\n",
    "# numpy.random.seed(seed)\n",
    "# model = Sequential()\n",
    "# # model.add(Dense(102, input_dim=102, kernel_initializer='uniform', activation='relu'))\n",
    "# # model.add(Dense(10, kernel_initializer='uniform', activation='relu'))\n",
    "# # model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# model.add(Conv2D(32, (5,5), input_shape=(1,10,10), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# # model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32,kernel_initializer='uniform',activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile model\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# # Fit the model\n",
    "# model.fit(X_train_cnn, my_y_train_BOOL, epochs=30, batch_size=10,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal n_estimators: 35\n",
      "Optimal max_depth: 18\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Optimize n_estimators, max_depth in random forest\n",
    "# --------------\n",
    "dt_rforest = ensemble.RandomForestClassifier(max_depth=3)\n",
    "rforest = dt_rforest.fit(my_x_train, my_y_train)\n",
    "\n",
    "parameters = {'max_depth': [12, 14, 16, 18, 20, 22, 24], 'n_estimators': [20, 25, 30, 35, 40]}\n",
    "rforest = cv_optimize(rforest, parameters, my_x_train, my_y_train, n_jobs=10, n_folds=5, score_func=None)\n",
    "print 'Optimal n_estimators: ' + str(rforest.n_estimators)\n",
    "print 'Optimal max_depth: ' + str(rforest.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest score: 0.713528836095\n",
      "Compute Time 15.1984391212\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Random Forest\n",
    "# --------------\n",
    "start_time = time.time()\n",
    "dt_rforest = ensemble.RandomForestClassifier(max_depth = 14, n_estimators = 100)\n",
    "dt_rforest.fit(my_x_train, my_y_train)\n",
    "compute_time = time.time() - start_time\n",
    "\n",
    "print \"Random forest score: \" + str(dt_rforest.score(my_x_test, my_y_test))\n",
    "print \"Compute Time\", compute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_rforest.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_rf = dt_rforest.predict_proba(my_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds=preds_rf[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.286471\n",
      "correct=0.713529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56167985757320515"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = my_y_test_BOOL \n",
    "print ('error=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))))  \n",
    "print ('correct=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)==labels[i]) /float(len(preds))))  \n",
    "discrepancy(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal n_neighbors: 21\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Optimize n_neighbors in KNN\n",
    "# --------------\n",
    "dt_KNN = KNN(n_neighbors=5, weights='distance', n_jobs=10)\n",
    "mKNN = dt_KNN.fit(my_x_train, my_y_train)\n",
    "\n",
    "KNN_params = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]}\n",
    "mKNN = cv_optimize(mKNN, KNN_params, my_x_train, my_y_train, n_jobs=10, n_folds=5, score_func=None)\n",
    "print 'Optimal n_neighbors: ' + str(mKNN.n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN score: 0.676880504843\n",
      "Compute Time 0.908000946045\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# KNN\n",
    "# --------------\n",
    "start_time = time.time()\n",
    "dt_KNN = KNN(n_neighbors=21, weights='distance', n_jobs=10)\n",
    "mKNN = dt_KNN.fit(my_x_train, my_y_train)\n",
    "compute_time = time.time() - start_time\n",
    "\n",
    "print \"KNN score: \" + str(mKNN.score(my_x_test, my_y_test))\n",
    "print \"Compute Time\", compute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_KNN.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradBoosting score: 0.714406236291\n",
      "Compute Time 34.2602109909\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mGBoost = GBoost()\n",
    "mGBoost.fit(my_x_train, my_y_train)\n",
    "compute_time = time.time() - start_time\n",
    "\n",
    "print \"GradBoosting score: \" + str(mGBoost.score(my_x_test, my_y_test))\n",
    "print \"Compute Time\", compute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mGBoost.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discrepancy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal n_estimators: 60\n"
     ]
    }
   ],
   "source": [
    "# --------------\n",
    "# Optimize Bagging\n",
    "# --------------\n",
    "mBag = Bagging()\n",
    "mBag.fit(my_x_train, my_y_train)\n",
    "compute_time = time.time() - start_time\n",
    "\n",
    "Bag_params = {'n_estimators': [10, 20, 30, 40, 50, 60]}\n",
    "mBag = cv_optimize(mBag, Bag_params, my_x_train, my_y_train, n_jobs=10, n_folds=5, score_func=None)\n",
    "print 'Optimal n_estimators: ' + str(mBag.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging score: 0.702932541423\n",
      "Compute Time 26.4830219746\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mBag = Bagging(n_estimators=60, n_jobs=10)\n",
    "mBag.fit(my_x_train, my_y_train)\n",
    "compute_time = time.time() - start_time\n",
    "\n",
    "print \"Bagging score: \" + str(mBag.score(my_x_test, my_y_test))\n",
    "print \"Compute Time\", compute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mBag.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------\n",
    "# Optimize SVM\n",
    "# --------------\n",
    "dt_SVM = SVC(C=50, kernel='linear')\n",
    "mSVM = dt_SVM.fit(my_x_train, my_y_train)\n",
    "\n",
    "SVM_params = {'C': [800, 1000, 1200, 1400, 1600]}\n",
    "mSVM = cv_optimize(mSVM, SVM_params, my_x_train, my_y_train, n_jobs=10, n_folds=5, score_func=None)\n",
    "print 'Optimal C: ' + str(mSVM.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------\n",
    "# SVM\n",
    "# --------------\n",
    "start_time = time.time()\n",
    "dt_SVM = SVC(C=1000, kernel='linear')\n",
    "mSVM = dt_SVM.fit(my_x_train, my_y_train)\n",
    "compute_time = time.time() - start_time\n",
    "\n",
    "print \"SVM score: \" + str(mSVM.score(my_x_test, my_y_test))\n",
    "print \"Compute Time\", compute_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mSVM.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest_x = xgb.DMatrix(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.58592987  0.36058328  0.74859029  0.55805337  0.78490901]\n",
      "(39510,)\n"
     ]
    }
   ],
   "source": [
    "pred_y = bst.predict(dtest_x)\n",
    "print pred_y[0:5]\n",
    "print np.shape(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44791708  0.55208292]\n",
      " [ 0.48620226  0.51379774]\n",
      " [ 0.24798737  0.75201263]\n",
      " [ 0.44153553  0.55846447]\n",
      " [ 0.24635485  0.75364515]]\n"
     ]
    }
   ],
   "source": [
    "pred_y = dt_rforest.predict_proba(test_x)\n",
    "print pred_y[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.43069753  0.56930247]\n",
      " [ 0.4121044   0.5878956 ]\n",
      " [ 0.33823453  0.66176547]\n",
      " [ 0.43047334  0.56952666]\n",
      " [ 0.06307356  0.93692644]]\n"
     ]
    }
   ],
   "source": [
    "pred_y = dt_KNN.predict_proba(test_x)\n",
    "print pred_y[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33929182  0.66070818]\n",
      " [ 0.55804637  0.44195363]\n",
      " [ 0.27185358  0.72814642]\n",
      " [ 0.32067297  0.67932703]\n",
      " [ 0.20513272  0.79486728]]\n"
     ]
    }
   ],
   "source": [
    "pred_y = mGBoost.predict_proba(test_x)\n",
    "print pred_y[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n",
      "/Applications/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/hashing.py:197: DeprecationWarning: Changing the shape of non-C contiguous array by\n",
      "descriptor assignment is deprecated. To maintain\n",
      "the Fortran contiguity of a multidimensional Fortran\n",
      "array, use 'a.T.view(...).T' instead\n",
      "  obj_bytes_view = obj.view(self.np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5         0.5       ]\n",
      " [ 0.5         0.5       ]\n",
      " [ 0.38333333  0.61666667]\n",
      " [ 0.28333333  0.71666667]\n",
      " [ 0.11666667  0.88333333]]\n"
     ]
    }
   ],
   "source": [
    "pred_y = mBag.predict_proba(test_x)\n",
    "print pred_y[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>voted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.585930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.360583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.748590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.558053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.784909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     voted\n",
       "0   1  0.585930\n",
       "1   2  0.360583\n",
       "2   3  0.748590\n",
       "3   4  0.558053\n",
       "4   5  0.784909"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame(test_filled['Id'])\n",
    "#df_pred['voted'] = pd.Series(pred_y[:,1], index=df_pred.index)\n",
    "df_pred['voted'] = pd.Series(pred_y[:], index=df_pred.index)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_pred.to_csv('pred_RF_d18_n35.csv',index=False)\n",
    "#df_pred.to_csv('pred_KNN_k21.csv',index=False)\n",
    "#df_pred.to_csv('pred_GBoost.csv',index=False)\n",
    "df_pred.to_csv('pred_xgboost3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
